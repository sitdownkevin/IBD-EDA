{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_csv('./data/icu_ibd_all_table.csv')\n",
    "    .assign(intime = lambda x: pd.to_datetime(x['intime']))\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2417, 6)\n",
      "   subject_id gender  anchor_age anchor_year anchor_year_group  dod\n",
      "0    10098672      M          61  2140-01-01       2011 - 2013  NaN\n",
      "1    10303503      F          23  2144-01-01       2008 - 2010  NaN\n",
      "2    10312715      M          39  2176-01-01       2008 - 2010  NaN\n",
      "3    10318500      F          46  2194-01-01       2011 - 2013  NaN\n",
      "4    10410021      M          49  2135-01-01       2011 - 2013  NaN\n"
     ]
    }
   ],
   "source": [
    "df2 = (\n",
    "    pd.read_csv('./data/patients_ibd.csv')\n",
    "    .assign(anchor_year=lambda x: pd.to_datetime(x['anchor_year'].astype(str) + '-01-01'))\n",
    ")\n",
    "\n",
    "print(df2.shape)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1161, 31)\n",
      "       hadm_id  subject_id              intime      los  mortality  gender  \\\n",
      "327   22643604    10024331 2141-03-18 19:36:08  4.10571          1       1   \n",
      "1022  28899194    10025647 2176-09-22 17:57:15  1.96810          1       1   \n",
      "896   27617929    10037975 2185-01-17 19:12:12  4.87824          1       1   \n",
      "110   20845468    10048262 2168-08-21 00:21:53  0.44588          0       1   \n",
      "908   27715453    10056223 2122-09-23 15:08:45  5.04106          0       1   \n",
      "\n",
      "            age  weight  bmi  heart_rate  ...  hemoglobin  CRP  \\\n",
      "327   73.210959     NaN  NaN        70.0  ...         9.4  NaN   \n",
      "1022  84.726027     NaN  NaN        70.0  ...        10.5  NaN   \n",
      "896   60.043836     NaN  NaN        90.0  ...        12.5  NaN   \n",
      "110   46.641096     NaN  NaN       101.0  ...         NaN  NaN   \n",
      "908   50.728767     NaN  NaN        89.0  ...         9.4  NaN   \n",
      "\n",
      "                             race  language  marital_status  insurance  \\\n",
      "327                         WHITE   ENGLISH         MARRIED   Medicare   \n",
      "1022                        WHITE   ENGLISH         MARRIED   Medicare   \n",
      "896                       UNKNOWN   ENGLISH         MARRIED   Medicare   \n",
      "110                         WHITE   ENGLISH         MARRIED   Medicare   \n",
      "908   HISPANIC/LATINO - DOMINICAN         ?          SINGLE   Medicaid   \n",
      "\n",
      "      die_in_icu  uc_only  cd_only  uc_cd  \n",
      "327            0        1        0      0  \n",
      "1022           0        1        0      0  \n",
      "896            1        0        1      0  \n",
      "110            0        1        0      0  \n",
      "908            0        1        0      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "data = (\n",
    "    df.merge(\n",
    "        df2[['subject_id', 'anchor_year']], \n",
    "        on='subject_id', \n",
    "        how='left',\n",
    "    ) # 需要 df2 的 anchor_year 信息\n",
    "    .sort_values(by=['subject_id', 'intime'],) # 每个 subject_id 按照入院时间 intime 排序\n",
    "    .assign(\n",
    "        age = lambda x: ((x['intime'] - x['anchor_year']).dt.days) / 365 + x['age']\n",
    "    )\n",
    "    .drop(columns=['outtime', 'anchor_year'])\n",
    ")\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns (Missing Value + Useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值过多的字段\n",
      "['weight', 'bmi', 'systolic_pressure', 'diastolic_pressure', 'temperature', 'white_blood_cell', 'red_blood_cell', 'CRP']\n"
     ]
    }
   ],
   "source": [
    "# 删除缺失值过多的字段\n",
    "cols_missing = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].isna().sum() / data.shape[0]*100 > 5:\n",
    "        cols_missing.append(col)\n",
    "        # print(\n",
    "        #     f'{col} => '\n",
    "        #     f'NA Count: {data[col].isna().sum()} ({data[col].isna().sum() / data.shape[0]*100:.2f}%)'\n",
    "        #     '\\n'\n",
    "        # )\n",
    "\n",
    "print('缺失值过多的字段')\n",
    "print(cols_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手动删除的字段\n",
      "['hadm_id', 'mortality']\n"
     ]
    }
   ],
   "source": [
    "# 删除不需要的字段\n",
    "cols_useless = [\n",
    "    'hadm_id',\n",
    "    'mortality',\n",
    "]\n",
    "\n",
    "print('手动删除的字段')\n",
    "print(cols_useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols (before): 31\n",
      "Cols (after): 21\n"
     ]
    }
   ],
   "source": [
    "cols_except = cols_missing + cols_useless\n",
    "\n",
    "print(f'Cols (before): {data.shape[1]}')\n",
    "data.drop(columns=cols_except, inplace=True)\n",
    "print(f'Cols (after): {data.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Rows (Missing Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows (before): 1161\n",
      "Rows (after): 1127\n"
     ]
    }
   ],
   "source": [
    "# 删除缺失值过多的行\n",
    "print(f'Rows (before): {data.shape[0]}')\n",
    "data = data[~(data.isna().sum(axis=1) > (data.shape[1]+1)*0.05)]\n",
    "print(f'Rows (after): {data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_race(race):\n",
    "    if 'WHITE' in race:\n",
    "        return 'WHITE'\n",
    "    elif 'BLACK' in race:\n",
    "        return 'BLACK'\n",
    "    elif 'HISPANIC' in race or 'LATINO' in race:\n",
    "        return 'HISPANIC/LATINO'\n",
    "    elif 'ASIAN' in race:\n",
    "        return 'ASIAN'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "data.loc[:, 'race'] = data.loc[:, 'race'].apply(parse_race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 type 做 drop_first\n",
    "data.drop(columns=['uc_cd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count  percentage\n",
      "index                     \n",
      "ENGLISH   1073   95.208518\n",
      "?           54    4.791482\n",
      "\n",
      "                 count  percentage\n",
      "index                             \n",
      "WHITE              927   82.253771\n",
      "BLACK              102    9.050577\n",
      "OTHER               70    6.211180\n",
      "HISPANIC/LATINO     21    1.863354\n",
      "ASIAN                7    0.621118\n",
      "\n",
      "          count  percentage\n",
      "index                      \n",
      "MARRIED     512   45.430346\n",
      "SINGLE      369   32.741792\n",
      "WIDOWED     137   12.156167\n",
      "DIVORCED     95    8.429459\n",
      "NaN          14    1.242236\n",
      "\n",
      "          count  percentage\n",
      "index                      \n",
      "Medicare    524   46.495120\n",
      "Other       516   45.785271\n",
      "Medicaid     87    7.719610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 需要转换为 dummy variable 的字段\n",
    "cols = ['language', 'race', 'marital_status', 'insurance']\n",
    "\n",
    "for col in cols:\n",
    "    tmp = data[col].value_counts(dropna=False)\n",
    "    res = pd.DataFrame({'index': tmp.index, 'count': tmp.values, 'percentage': tmp.values/tmp.sum()*100})\n",
    "    print(f'{res.set_index(\"index\")}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'intime', 'los', 'gender', 'age', 'heart_rate',\n",
       "       'respiratory_rate', 'hematocrit', 'rdw', 'platelet', 'mcv', 'mch',\n",
       "       'hemoglobin', 'die_in_icu', 'uc_only', 'cd_only', 'language_ENGLISH',\n",
       "       'race_BLACK', 'race_HISPANIC/LATINO', 'race_OTHER', 'race_WHITE',\n",
       "       'marital_status_MARRIED', 'marital_status_SINGLE',\n",
       "       'marital_status_WIDOWED', 'insurance_Medicare', 'insurance_Other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理 dummy variables\n",
    "data = pd.get_dummies(data=data, \n",
    "                      columns=cols, \n",
    "                      prefix=cols, \n",
    "                      drop_first=True)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add ICU Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['icu_count'] = (\n",
    "    data.sort_values(by=['subject_id', 'intime'])\n",
    "    .groupby('subject_id').cumcount() + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'heart_rate', 'respiratory_rate', 'hematocrit', 'rdw', 'platelet', 'mcv', 'mch', 'hemoglobin', 'icu_count']\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data[cols] = scaler.fit_transform(data[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换所有 bool 类型为 int\n",
    "for k, v in data.dtypes.items():\n",
    "    if v == bool:\n",
    "        data[k] = data[k].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First ICU Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Statistics\n",
    "(\n",
    "    data\n",
    "    # .drop_duplicates(subset='subject_id', keep='first',)\n",
    "    .drop(columns=['subject_id', 'intime',])\n",
    "    .to_csv('./data_processed/data_stats_.csv')\n",
    "    # .columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    data\n",
    "    # .drop_duplicates(subset='subject_id', keep='first',)\n",
    "    # .drop(columns=['die_in_icu'])\n",
    "    .to_csv('./data_processed/data_first_record_.csv')\n",
    "    # .columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(data['los'],\n",
    "            data['subject_id'], \n",
    "            alpha=0.9, \n",
    "            s=data['icu_count']*100,\n",
    "            c=data['subject_id'].astype('category').cat.codes,\n",
    "            cmap='viridis'\n",
    "            )  # alpha用于设置点的透明度\n",
    "\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8), dpi=300)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "color_labels = data['subject_id'].astype('category').cat.codes\n",
    "\n",
    "scatter = ax.scatter(data['los'], \n",
    "                     data['subject_id'], \n",
    "                     data['icu_count'],  # 将icu_count作为第三个维度\n",
    "                     alpha=0.9, \n",
    "                     s=np.exp(data['icu_count']*5),  # 也可以使用icu_count调整点的大小\n",
    "                     c=color_labels, \n",
    "                     cmap='jet')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Length of Stay (days)')\n",
    "ax.set_ylabel('Subject ID')\n",
    "ax.set_zlabel('ICU Count')\n",
    "ax.set_title('3D Plot of ICU Data')\n",
    "\n",
    "plt.colorbar(scatter, ax=ax, label='Subject ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.merge(df2[['subject_id', 'anchor_year_group']],\n",
    "           on='subject_id', how='left').anchor_year_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
