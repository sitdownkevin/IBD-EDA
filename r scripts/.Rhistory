cat("Accuracy:", accuracy, "\n")
## Calculate Recall
recall <- diag(confusion_matrix)[1] / sum(confusion_matrix[1,])
cat("Recall:", recall, "\n")
## Calculate F1 Score
precision <- diag(confusion_matrix)[1] / colSums(confusion_matrix)[1]
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
library(pROC)
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)
# Plot the ROC curve
plot(
roc_obj,
col = "blue",
main = "ROC Curve - ANN (Cross-Validation)",
legacy.axes = TRUE,
print.auc = TRUE,
print.thres = TRUE,
grid = c(0.2, 0.2),
grid.col = c("green", "orange")
)
X <- read.csv("./data/X_.csv", header = TRUE)
y <- read.csv("./data/y_.csv", header = TRUE)
data <- cbind(X, y)
indices <- 1:nrow(data)
set.seed(123) # <=
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices)) # <=
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
library('MASS')
library('caret')
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary.glm(step_model)
# ci <- confint(step_model)
# exp(cbind(OR <- coef(step_model), ci))
# predictions <- predict(step_model, test_data, type="response")
ci <- confint(step_model)
exp(cbind(OR <- coef(step_model), ci))
predictions <- predict(step_model, test_data, type="response")
confusion_matrix <- table(test_data[, ncol(test_data)], ifelse(predictions > 0.5, 1, 0))
## 计算准确率
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
## 计算召回率
recall <- diag(confusion_matrix) / rowSums(confusion_matrix)
cat("Recall:", recall, "\n")
## 计算F1分数
precision <- diag(confusion_matrix) / colSums(confusion_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
library(pROC)
roc_obj <- roc(test_data[, ncol(test_data)], predictions)
plot(
roc_obj,
col = "red",
main = "ROC Curve - Logistic Regression",
legacy.axes = T, # y轴格式更改
print.auc = TRUE, # 显示AUC面积
print.thres = TRUE, # 添加截点和95%CI
grid=c(0.2,0.2),
grid.col=c("blue","yellow")
)
summary.glm(step_model)
ci <- confint(step_model)
exp(cbind(OR <- coef(step_model), ci))
predictions <- predict(step_model, test_data, type="response")
X <- read.csv("./data/X_.csv", header = TRUE)
y <- read.csv("./data/y_.csv", header = TRUE)
# 定义初始模型
new_formula <- dod ~ age + X25000 + X2639 + X2761 + X2762 + X2768 + X27800 + X2875 + X3051 + X311 + X32723 + X4019 + X40390 + X412 + X4280 + X496 + X51881 + X5589 + X56089 + X56400 + X56722 + X5990 + X78659 + X99592 + X99859 + D649 + E8490 + F419 + K219 + N179 + V1582 + V442 + V5866 + Z9049
new_model <- glm(formula = initial_formula, family = binomial, data = train_data)
# 定义初始模型
new_formula <- dod ~ age + X25000 + X2639 + X2761 + X2762 + X2768 + X27800 + X2875 + X3051 + X311 + X32723 + X4019 + X40390 + X412 + X4280 + X496 + X51881 + X5589 + X56089 + X56400 + X56722 + X5990 + X78659 + X99592 + X99859 + D649 + E8490 + F419 + K219 + N179 + V1582 + V442 + V5866 + Z9049
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
# 定义初始模型
new_formula <- dod ~ age + X25000 + X2639 + X2761 + X2762 + X2768 + X27800 + X2875 + X3051 + X311 + X32723 + X4019 + X40390 + X412 + X4280 + X496 + X51881 + X5589 + X56089 + X56400 + X56722 + X5990 + X78659 + X99592 + X99859 + D649 + E8490 + F419 + K219 + N179 + V1582 + V442 + V5866 + Z9049
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
cat(summary_model)
# 定义初始模型
new_formula <- dod ~ age + X25000 + X2639 + X2761 + X2762 + X2768 + X27800 + X2875 + X3051 + X311 + X32723 + X4019 + X40390 + X412 + X4280 + X496 + X51881 + X5589 + X56089 + X56400 + X56722 + X5990 + X78659 + X99592 + X99859 + D649 + E8490 + F419 + K219 + N179 + V1582 + V442 + V5866 + Z9049
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
print(summary_model)
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
summary_model
new_formula
type(new_formula)
new_formula
update(new_formula, . ~ .)
update(new_formula, . ~ . - Z9049)
new_formula
max_p_value_attribute
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
new_formula
update(new_formula, . ~ . - max_p_value_attribute)
update(new_formula, . ~ . - K219)
as.name(max_p_value_attribute)
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- as.name(names(p_values)[max_p_value_index])
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- as.name(names(p_values)[max_p_value_index])
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- as.name(names(p_values)[max_p_value_index])
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
new_formula
new_formula
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_formula
update(new_formula, . ~ . - max_p_value_attribute)
update(new_formula, . ~ . - as.name(max_p_value_attribute))
# 获取最大 p 值的属性
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
update(new_formula, . ~ . - max_p_value_attribute)
update(new_formula, . ~ . - Z9049)
update(new_formula, . ~ . - D649)
p_values
# 获取最大 p 值的属性
library(stats)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
library(stats)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
library(stats)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
library(stats)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
# 创建新的公式并移除最大 p 值的属性
new_formula <- update(new_formula, . ~ . - max_p_value_attribute)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
# 查看更新后的模型摘要
summary_model <- summary.glm(new_model)
update(new_formula, . ~ . - max_p_value_attribute)
update(new_formula, . ~ . - N179)
# 定义初始模型
new_formula <- dod ~ age + X25000 + X2639 + X2761 + X2762 + X2768 + X27800 + X2875 + X3051 + X311 + X32723 + X4019 + X40390 + X412 + X4280 + X496 + X51881 + X5589 + X56089 + X56400 + X56722 + X5990 + X78659 + X99592 + X99859 + D649 + E8490 + F419 + K219 + N179 + V1582 + V442 + V5866 + Z9049
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
new_formula <- update(new_formula, . ~ . - K219)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
new_formula <- update(new_formula, . ~ . - K219)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute, max(p_values))
new_formula <- update(new_formula, . ~ . - K219)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute, max(p_values))
new_formula <- update(new_formula, . ~ . - K219)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute, max(p_values))
new_formula <- update(new_formula, . ~ . - E8490)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute, max(p_values))
new_formula <- update(new_formula, . ~ . - E8490)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - Z9049)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X2639)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X5589)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - V5866)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X496)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X56400)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - V442)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X4019)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X56722)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X2768)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X99859)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X40390)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
new_formula <- update(new_formula, . ~ . - X78659)
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
summary_model <- summary(new_model)
p_values <- summary_model$coefficients[, "Pr(>|z|)"]
max_p_value_index <- which.max(p_values)
max_p_value_attribute <- names(p_values)[max_p_value_index]
print(max_p_value_attribute)
print(max(p_values))
summary.glm(new_model)
ci <- confint(new_model)
exp(cbind(OR <- coef(new_model), ci))
set.seed(123) # Set seed for reproducibility
# Combine X and y into a single dataframe
data <- cbind(X, y)
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, ncol(test_data)])
}
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0)))
## Calculate Accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
## Calculate Recall
recall <- diag(confusion_matrix)[1] / sum(confusion_matrix[1,])
cat("Recall:", recall, "\n")
## Calculate F1 Score
precision <- diag(confusion_matrix)[1] / colSums(confusion_matrix)[1]
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)
# Plot the ROC curve
plot(
roc_obj,
col = "blue",
main = "ROC Curve - Logistic Regression (Cross-Validation)",
legacy.axes = TRUE,
print.auc = TRUE,
grid = c(0.2, 0.2),
grid.col = c("green", "orange")
)
X <- read.csv("./data/X_.csv", header = TRUE)
y <- read.csv("./data/y_.csv", header = TRUE)
new_formula <- dod ~ age + X25000 + X2761 + X2762 + X27800 + X2875 + X3051 + X311 + X32723 + X412 + X4280 + X51881 + X56089 + X5990 + X99592 + D649 + F419 + N179 + V1582
set.seed(123) # Set seed for reproducibility
# Combine X and y into a single dataframe
data <- cbind(X, y)
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, ncol(test_data)])
}
set.seed(123) # Set seed for reproducibility
# Combine X and y into a single dataframe
data <- cbind(X, y)
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, ncol(test_data)])
}
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0)))
## Calculate Accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
## Calculate Recall
recall <- diag(confusion_matrix)[1] / sum(confusion_matrix[1,])
cat("Recall:", recall, "\n")
## Calculate F1 Score
precision <- diag(confusion_matrix)[1] / colSums(confusion_matrix)[1]
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)
# Plot the ROC curve
plot(
roc_obj,
col = "blue",
main = "ROC Curve - Logistic Regression (Cross-Validation)",
legacy.axes = TRUE,
print.auc = TRUE,
grid = c(0.2, 0.2),
grid.col = c("green", "orange")
)
