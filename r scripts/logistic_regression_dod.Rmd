---
title: Logistic Regression
output:
  html_document: 
    toc: yes
  pdf_document: default
---

## Load Dataset

```{r}
X <- read.csv("./data/X.csv", header = TRUE)
y <- read.csv("./data/y.csv", header = TRUE)
```

## Dataset Division

```{r}
data <- cbind(X, y)

indices <- 1:nrow(data)
# set.seed(123) # <=
shuffled_indices <- sample(indices) 
train_size <- floor(0.7 * length(indices)) # <=

train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]

```

## Logistic Regression using stepAIC

```{r}
library('MASS')
library('caret')

logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary.glm(step_model)

ci <- confint(step_model)
exp(cbind(OR <- coef(step_model), ci))

predictions <- predict(step_model, test_data, type="response")
```

## Performance

```{r}
confusion_matrix <- table(test_data[, ncol(test_data)], ifelse(predictions > 0.5, 1, 0))

## 计算准确率
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")

## 计算召回率
recall <- diag(confusion_matrix) / rowSums(confusion_matrix)
cat("Recall:", recall, "\n")

## 计算F1分数
precision <- diag(confusion_matrix) / colSums(confusion_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")

```

# Re-run

```{r}
new_model <- glm(formula = dod ~ age + X2639 + X2761 + X2762 + X27800 + X2875 + X3051 + X311 + X32723 + X412 + X4280 + X51881 + X56089 + X56722 + X5849 + X5990 + X99592 + X99859 + D649 + F419 + N179 + V1582 + X25000 , family = binomial, data = train_data)

summary.glm(new_model)

predictions <- predict(new_model, test_data, type="response")

```

# ROC Curve

```{r}
library(pROC)
roc_obj <- roc(test_data[, ncol(test_data)], predictions)

plot(
  roc_obj,
  col = "red", 
  main = "ROC Curve - Logistic Regression",
  legacy.axes = T, # y轴格式更改
  print.auc = TRUE, # 显示AUC面积
  print.thres = TRUE, # 添加截点和95%CI
  grid=c(0.2,0.2),
  grid.col=c("blue","yellow")
)
```

## Cross Validation Logistic Regression

```{r}
set.seed(123) # Set seed for reproducibility

# Combine X and y into a single dataframe
data <- cbind(X, y)


# Perform 5-fold cross-validation
num_folds <- 5
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)

# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()

for (i in 1:num_folds) {
  indices <- 1:nrow(data)
  shuffled_indices <- sample(indices) 
  train_size <- floor(0.7 * length(indices)) # <=
  
  train_indices <- shuffled_indices[1:train_size]
  test_indices <- shuffled_indices[(train_size + 1):length(indices)]
  train_data <- data[train_indices, ]
  test_data <- data[test_indices, ]
  
  # Split the data into training and test sets for the current fold
  logit_model <- glm(dod ~ ., data = train_data, family = binomial)
  
  new_model <- glm(formula = dod ~ age + X2639 + X2761 + X2762 + X27800 + X2875 + X3051 + X311 + X32723 + X412 + X4280 + X51881 + X56089 + X56722 + X5849 + X5990 + X99592 + X99859 + D649 + F419 + N179 + V1582 + X25000 , family = binomial, data = train_data)

  # summary.glm(new_model)
  predictions <- predict(new_model, test_data, type="response")

  # Append the predictions and actual values to the vectors
  all_predictions <- c(all_predictions, predictions)
  all_actuals <- c(all_actuals, test_data[, ncol(test_data)])
}

# Calculate performance metrics on the entire dataset
confusion_matrix <- table(as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0)))

## Calculate Accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")

## Calculate Recall
recall <- diag(confusion_matrix)[1] / sum(confusion_matrix[1,])
cat("Recall:", recall, "\n")

## Calculate F1 Score
precision <- diag(confusion_matrix)[1] / colSums(confusion_matrix)[1]
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")

```

## Cross Validation Logistic Regression

```{r}
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)

# Plot the ROC curve
plot(
  roc_obj,
  col = "blue",
  main = "ROC Curve - Logistic Regression (Cross-Validation)",
  legacy.axes = TRUE,
  print.auc = TRUE,
  grid = c(0.2, 0.2),
  grid.col = c("green", "orange")
)
```
