---
title: Cross-Validation Logistic Regression
output:
  html_document: 
    toc: yes
  pdf_document: default
---

# Load Dataset

```{r}
library(dplyr)

read.csv('../data/data_kept.csv') %>%
  select(-c(subject_id, X, gender_F, language_.)) -> 
  data

```

# Initial Model
```{r}
new_formula <- dod ~ marital_status_MARRIED + race_BLACK + first_age + V1582 + X5990 + X3051 + X25000 + X2761 + X2762 + X56089 + X4280 + F419 + X40390 + V5866 + X56400 + X2875 + X5589 + X2639 + X99592 + V4986 + D649 + X51881 + X78659 + X412

```


# Cross Validation 

## Logistic Regression

```{r}
set.seed(314) # Set seed for reproducibility


# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)

# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()

for (i in 1:num_folds) {
  # Split the data into training and test sets for the current fold
  train_data <- data[folds != i, ]
  test_data <- data[folds == i, ]
  
  # Logistic Regression
  new_model <- glm(formula = new_formula, family = binomial, data = train_data)

  predictions <- predict(new_model, test_data, type="response")

  # Append the predictions and actual values to the vectors
  all_predictions <- c(all_predictions, predictions)
  all_actuals <- c(all_actuals, test_data[, 1])
}

```

## Performance

```{r}
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(
  as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)

TP <- confusion_matrix[1, 1]
TN <- confusion_matrix[2, 2]
FP <- confusion_matrix[2, 1]
FN <- confusion_matrix[1, 2]

## Calculate Accuracy
accuracy <- (TP + TN) / (TP + FP + TN + FN)
cat("Accuracy:", accuracy, "\n")

## Calculate Recall
recall <- TP / (TP + FN)
cat("Recall:", recall, "\n")

## Calculate Precision
precision <- TP / (TP + FP)
cat("Precision:", precision, "\n")

## Calculate Specificity
specificity <- TN / (TN + FP)
cat("Specificity:", specificity, "\n")

## Calculate F1 Score
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
```

## ROC Curve

```{r}
library(pROC)
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)

# Plot the ROC curve
plot(
  roc_obj,
  col = "blue",
  main = "ROC Curve - Logistic Regression (Cross-Validation)",
  legacy.axes = TRUE,
  print.auc = TRUE,
  print.thres = TRUE,
  grid = c(0.2, 0.2),
  grid.col = c("green", "orange")
)
```
