---
title: Random Forest
output:
  html_document: 
    toc: yes
  pdf_document: default
---

# Load Dataset

```{r}
X <- read.csv("./data/X_.csv", header = TRUE)
y <- read.csv("./data/y_.csv", header = TRUE)
```

# Dataset Division

```{r}
data <- cbind(X, y)

set.seed(123) # 123
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices))
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]

train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
```

# Random Forest

```{r}
library(randomForest)

train_X <- as.matrix(train_data[, -ncol(train_data)])
train_y <- train_data[, ncol(train_data)]

rf_model <- randomForest(train_X, train_y)

test_X <- as.matrix(test_data[, -ncol(test_data)])
test_y <- test_data[, ncol(test_data)]

predictions <- predict(rf_model, test_X)
```

# Performance

```{r}
confusion_matrix <- table(as.numeric(test_y), as.numeric(ifelse(predictions > 0.5, 1, 0)))

## 计算 Accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")

## 计算 Recall
recall <- diag(confusion_matrix)[1] / sum(confusion_matrix[1,])
cat("Recall:", recall, "\n")

## 计算 F1 Score
precision <- diag(confusion_matrix)[1] / colSums(confusion_matrix)[1]
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")

```

# ROC Curve

```{r}
library(pROC)
roc_obj <- roc(as.numeric(test_y), 
               as.numeric(predictions),)

plot(
  roc_obj,
  col = "red", 
  main = "ROC Curve - Random Forest",
  legacy.axes = T, 
  print.auc = TRUE,
  print.thres = TRUE,
  grid=c(0.2,0.2),
  grid.col=c("blue","yellow")
)
```


