]
test_data[, -'dod']
# Make predictions on the test set
predictions <- compute(trained_model, test_data)$net.result
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 'dod'])
# Make predictions on the test set
predictions <- compute(trained_model, select(test_data, -dod))$net.result
library(dplyr)
# ANN
ann_formula <- as.formula("dod ~ .")
ann_model <- neuralnet(ann_formula, data = train_data, hidden = c(20, 10), linear.output = FALSE, act.fct = "logistic")
trained_model <- ann_model
# Make predictions on the test set
predictions <- compute(trained_model, select(test_data, -dod))$net.result
# Make predictions on the test set
predictions <- compute(trained_model, test_data[,2:ncol(test_data)])$net.result
```{r}
read.csv('../data/data_kept.csv', header = TRUE) -> data
read.csv('../data/data_kept.csv', header = TRUE) -> data
# Cross Validation
## ANN Training
```{r}
library(neuralnet)
set.seed(123) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# ANN
ann_formula <- as.formula("dod ~ .")
ann_model <- neuralnet(ann_formula, data = train_data, hidden = c(20, 10), linear.output = FALSE, act.fct = "logistic")
trained_model <- ann_model
# Make predictions on the test set
predictions <- compute(trained_model, test_data[,2:ncol(test_data)])$net.result
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 'dod'])
}
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 'dod'])
}
## Performance
```{r}
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# ANN
ann_formula <- as.formula("dod ~ .")
ann_model <- neuralnet(ann_formula, data = train_data, hidden = c(20, 10), linear.output = FALSE, act.fct = "logistic")
trained_model <- ann_model
# Make predictions on the test set
predictions <- compute(trained_model, test_data[,2:ncol(test_data)])$net.result
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 'dod'])
}
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# ANN
ann_formula <- as.formula("dod ~ .")
ann_model <- neuralnet(ann_formula, data = train_data, hidden = c(20, 10), linear.output = FALSE, act.fct = "logistic")
trained_model <- ann_model
# Make predictions on the test set
predictions <- compute(trained_model, test_data[,2:ncol(test_data)])$net.result
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 'dod'])
}
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(
as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)
table(
as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)
read.csv('../data/data_kept.csv', header = TRUE) -> data
library(neuralnet)
set.seed(123) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
set.seed(314) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, ncol(test_data)])
}
read.csv('../data/data_kept.csv') -> data
read.csv('../data/data_kept.csv') -> data
# Initial Model
```{r}
# Cross Validation
## Logistic Regression
```{r}
set.seed(314) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, ncol(test_data)])
}
new_formula <- dod ~ marital_status_MARRIED + race_BLACK + first_age + V1582 + X5990 + X3051 + X25000 + X2761 + X2762 + X56089 + X4280 + F419 + X40390 + V5866 + X56400 + X2875 + X5589 + X2639 + X99592 + V4986 + D649 + X51881 + X78659 + X412
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, ncol(test_data)])
}
test_data
test_data[,1]
test_data[, 2]
test_data[, 3]
test_data[, dod]
test_data[, 'dod']
read.csv('./data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
library(dplyr)
read.csv('./data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
View(data)
variable_names[variable_names != "dod"] ->
variable_names
variable_names[variable_names != "dod"] ->
variable_names
data %>%
colnames() ->
variable_names
variable_names[variable_names != "dod"] ->
variable_names
new_formula <- dod ~ marital_status_MARRIED + race_BLACK + first_age + V1582 + X5990 + X3051 + X25000 + X2761 + X2762 + X56089 + X4280 + F419 + X40390 + V5866 + X56400 + X2875 + X5589 + X2639 + X99592 + V4986 + D649 + X51881 + X78659 + X412
set.seed(314) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
test_data
all_actuals <- c(all_actuals, test_data[, 3])
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 3])
}
## Performance
```{r}
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(
as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)
TP <- confusion_matrix[1, 1]
TN <- confusion_matrix[2, 2]
FP <- confusion_matrix[2, 1]
FN <- confusion_matrix[1, 2]
## Calculate Accuracy
accuracy <- (TP + TN) / (TP + FP + TN + FN)
cat("Accuracy:", accuracy, "\n")
## Calculate Recall
recall <- TP / (TP + FN)
cat("Recall:", recall, "\n")
## Calculate Precision
precision <- TP / (TP + FP)
cat("Precision:", precision, "\n")
library(dplyr)
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
data %>%
colnames() ->
variable_names
variable_names[variable_names != "dod"] ->
variable_names
new_formula <- dod ~ marital_status_MARRIED + race_BLACK + first_age + V1582 + X5990 + X3051 + X25000 + X2761 + X2762 + X56089 + X4280 + F419 + X40390 + V5866 + X56400 + X2875 + X5589 + X2639 + X99592 + V4986 + D649 + X51881 + X78659 + X412
set.seed(314) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 3])
}
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(
as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)
TP <- confusion_matrix[1, 1]
TN <- confusion_matrix[2, 2]
FP <- confusion_matrix[2, 1]
FN <- confusion_matrix[1, 2]
## Calculate Accuracy
accuracy <- (TP + TN) / (TP + FP + TN + FN)
cat("Accuracy:", accuracy, "\n")
## Calculate Recall
recall <- TP / (TP + FN)
cat("Recall:", recall, "\n")
## Calculate Precision
precision <- TP / (TP + FP)
cat("Precision:", precision, "\n")
## Calculate Specificity
specificity <- TN / (TN + FP)
cat("Specificity:", specificity, "\n")
## Calculate F1 Score
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
library(pROC)
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)
# Plot the ROC curve
plot(
roc_obj,
col = "blue",
main = "ROC Curve - Logistic Regression (Cross-Validation)",
legacy.axes = TRUE,
print.auc = TRUE,
print.thres = TRUE,
grid = c(0.2, 0.2),
grid.col = c("green", "orange")
)
read.csv('./data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
data %>%
colnames() ->
variable_names
variable_names[variable_names != "dod"] ->
variable_names
variable_names
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
View(data)
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
new_formula <- dod ~ marital_status_MARRIED + race_BLACK + first_age + V1582 + X5990 + X3051 + X25000 + X2761 + X2762 + X56089 + X4280 + F419 + X40390 + V5866 + X56400 + X2875 + X5589 + X2639 + X99592 + V4986 + D649 + X51881 + X78659 + X412
set.seed(314) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
train_data %>% colnames
train_data %>% colnames [1]
train_data %>% colnames %>% [1]
test_data[, 1]
test_data[, 0]
test_data[, 1]
all_actuals <- c(all_actuals, test_data[, 1])
library(dplyr)
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
new_formula <- dod ~ marital_status_MARRIED + race_BLACK + first_age + V1582 + X5990 + X3051 + X25000 + X2761 + X2762 + X56089 + X4280 + F419 + X40390 + V5866 + X56400 + X2875 + X5589 + X2639 + X99592 + V4986 + D649 + X51881 + X78659 + X412
set.seed(314) # Set seed for reproducibility
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# Logistic Regression
new_model <- glm(formula = new_formula, family = binomial, data = train_data)
predictions <- predict(new_model, test_data, type="response")
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 1])
}
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(
as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)
TP <- confusion_matrix[1, 1]
TN <- confusion_matrix[2, 2]
FP <- confusion_matrix[2, 1]
FN <- confusion_matrix[1, 2]
## Calculate Accuracy
accuracy <- (TP + TN) / (TP + FP + TN + FN)
cat("Accuracy:", accuracy, "\n")
## Calculate Recall
recall <- TP / (TP + FN)
cat("Recall:", recall, "\n")
## Calculate Precision
precision <- TP / (TP + FP)
cat("Precision:", precision, "\n")
## Calculate Specificity
specificity <- TN / (TN + FP)
cat("Specificity:", specificity, "\n")
## Calculate F1 Score
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
library(pROC)
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)
# Plot the ROC curve
plot(
roc_obj,
col = "blue",
main = "ROC Curve - Logistic Regression (Cross-Validation)",
legacy.axes = TRUE,
print.auc = TRUE,
print.thres = TRUE,
grid = c(0.2, 0.2),
grid.col = c("green", "orange")
)
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
library(dplyr)
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
library(neuralnet)
set.seed(123) # Set seed for reproducibility
# Combine X and y into a single dataframe
# data <- cbind(X, y)
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
# ANN
ann_formula <- as.formula("dod ~ .")
ann_model <- neuralnet(ann_formula, data = train_data, hidden = c(20, 10), linear.output = FALSE, act.fct = "logistic")
trained_model <- ann_model
# Make predictions on the test set
predictions <- compute(trained_model, test_data[,2:ncol(test_data)])$net.result
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data[, 1])
}
table(
as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)
# Calculate performance metrics on the entire dataset
confusion_matrix <- table(
as.numeric(all_actuals), as.numeric(ifelse(all_predictions > 0.5, 1, 0))
)
TP <- confusion_matrix[1, 1]
TN <- confusion_matrix[2, 2]
FP <- confusion_matrix[2, 1]
FN <- confusion_matrix[1, 2]
## Calculate Accuracy
accuracy <- (TP + TN) / (TP + FP + TN + FN)
cat("Accuracy:", accuracy, "\n")
## Calculate Recall
recall <- TP / (TP + FN)
cat("Recall:", recall, "\n")
## Calculate Precision
precision <- TP / (TP + FP)
cat("Precision:", precision, "\n")
## Calculate Specificity
specificity <- TN / (TN + FP)
cat("Specificity:", specificity, "\n")
## Calculate F1 Score
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1 Score:", f1_score, "\n")
library(pROC)
# Calculate ROC curve using the actual values and predictions
roc_obj <- roc(all_actuals, all_predictions)
# Plot the ROC curve
plot(
roc_obj,
col = "blue",
main = "ROC Curve - ANN (Cross-Validation)",
legacy.axes = TRUE,
print.auc = TRUE,
print.thres = TRUE,
grid = c(0.2, 0.2),
grid.col = c("green", "orange")
)
library(dplyr)
read.csv('../data/data_kept.csv') %>%
select(-c(subject_id, X, gender_F, language_.)) ->
data
library(randomForest)
set.seed(123) # Set seed for reproducibility
# Combine X and y into a single dataframe
# data <- cbind(X, y)
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
train_X <- as.matrix(train_data[, 2:ncol(test_data)])
train_y <- train_data[, ncol(train_data)]
test_X <- as.matrix(test_data[, 2:ncol(test_data)])
test_y <- test_data[, 1]
# Train the Bagged Tree model
bagged_tree <- randomForest(train_X, train_y, ntree = 100)
# Make predictions on the test set
predictions <- predict(bagged_tree, test_X)
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_y)
}
yes
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
library(randomForest)
set.seed(123) # Set seed for reproducibility
# Combine X and y into a single dataframe
# data <- cbind(X, y)
# Perform 10-fold cross-validation
num_folds <- 10
folds <- cut(seq(1, nrow(data)), breaks = num_folds, labels = FALSE)
# Create empty vectors to store the predictions and actual values
all_predictions <- vector()
all_actuals <- vector()
for (i in 1:num_folds) {
# Split the data into training and test sets for the current fold
train_data <- data[folds != i, ]
test_data <- data[folds == i, ]
train_X <- as.matrix(train_data[, 2:ncol(test_data)])
train_y <- train_data[, ncol(train_data)]
test_X <- as.matrix(test_data[, 2:ncol(test_data)])
test_y <- test_data[, 1]
# Train the Bagged Tree model
bagged_tree <- randomForest(train_X, train_y, ntree = 100)
# Make predictions on the test set
predictions <- predict(bagged_tree, test_X)
# Append the predictions and actual values to the vectors
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_y)
}
