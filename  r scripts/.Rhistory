setwd("~/Repo/gp-ibd")
setwd("~/Repo/gp-ibd/ r scripts")
library('MASS')
library('MASS')
X <- read.csv("X.csv")
View(X)
View(X)
X <- read.csv("X.csv", header = FALSE)
View(X)
View(X)
library('MASS')
X <- read.csv("X.csv", header = FALSE)
y <- read.csv("y.csv", header = FALSE)
data <- cbind(X, y)
View(data)
View(data)
logit_model <- glm(y ~ ., data = data, family = binomial)
View(data)
View(data)
X <- read.csv("X.csv", header = FALSE)
y <- read.csv("y.csv", header = FALSE)
data <- cbind(X, y)
View(data)
View(data)
View(data)
View(data)
X <- read.csv("X.csv", header = FALSE)
y <- read.csv("y.csv", header = FALSE)
data <- cbind(X, y)
View(data)
View(data)
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
View(data)
View(data)
View(data)
View(data)
data.header
data.headers
data
View(data)
View(data)
View(data)
library('MASS')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
logit_model <- glm(dod ~ ., data = data, family = binomial)
View(logit_model)
View(logit_model)
logit_model <- glm(dod ~ ., data = data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
View(step_model)
View(step_model)
View(step_model)
library('MASS')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
logit_model <- glm(dod ~ ., data = data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
# summary(step_model)
clear
cls
clean
library('MASS')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
logit_model <- glm(dod ~ ., data = data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
library('caret')
install.packages('caret')
library('caret')
library('MASS')
library('caret')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
set.seed(123) # 设置随机种子，以确保可重复性
train_indices <- createDataPartition(y$y, p = 0.7, list = FALSE) # 将数据划分为70%的训练集和30%的测试集
library('MASS')
library('caret')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
set.seed(123) # 设置随机种子，以确保可重复性
train_indices <- createDataPartition(y, p = 0.7, list = FALSE) # 将数据划分为70%的训练集和30%的测试集
View(y)
View(y)
y$y
x$x
x$y
X$y
X$x
X$x
X$
s
X$headers
indices <- 1:nrow(data)
indices
indices <- 1:nrow(data)
library('MASS')
library('caret')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices))
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
predict(step_model, newdata = test_data, type = "response")
library('MASS')
library('caret')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices))
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
test_predictions <- predict(step_model, newdata = test_data, type = "response")
threshold <- 0.5
test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
confusion_matrix <- confusionMatrix(test_predictions_binary, test_data$dod)
library('MASS')
library('caret')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices))
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
test_predictions <- predict(step_model, newdata = test_data, type = "response")
threshold <- 0.5
test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
library('MASS')
library('caret')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices))
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
test_predictions <- predict(step_model, newdata = test_data, type = "response")
threshold <- 0.5
test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
library('MASS')
library('caret')
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices))
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
test_predictions <- predict(step_model, newdata = test_data, type = "response")
threshold <- 0.5
test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
step_model
aic_r2 <- pR2(step_model, type = "aic")
pseudo_r2 <- pR2(step_model, type = "nagelkerke")
summary.glm(step_model)
ci <- confint(step_model)
ci
exp(coef(step_model))
exp(2)
exp(cbind(OR = coef(step_model, ci)))
ci
exp(cbind(OR = coef(step_model), ci))
library('MASS')
library('caret')
# 加载数据
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
# 合并数据集并划分
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices)) # 修改比例
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
# Logistic Regression using stepAIC
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary(step_model)
# test_predictions <- predict(step_model, newdata = test_data, type = "response")
# threshold <- 0.5
# test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
ci <- confint(step_model)
print(ci)
summary(step_model)
summary.glm(step_model)
exp(coef(step_model))
ci <- confint(step_model)
print(ci <- confint(step_model))
ci <- confint(step_model); print(ci)
print(ci)
exp(cbind(OR <- coef(step_model), ci))
exp(2)
library('MASS')
library('caret')
# 加载数据
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
# 合并数据集并划分
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices)) # 修改比例
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
# Logistic Regression using stepAIC
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary.glm(step_model)
# test_predictions <- predict(step_model, newdata = test_data, type = "response")
# threshold <- 0.5
# test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
ci <- confint(step_model)
print(ci)
exp(coef(step_model))
exp(cbind(OR <- coef(step_model), ci))
exp(coef(step_model));
exp(coef(step_model))
library('MASS')
library('caret')
# 加载数据
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
# 合并数据集并划分
data <- cbind(X, y)
set.seed(123)
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices)) # 修改比例
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
# Logistic Regression using stepAIC
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary.glm(step_model)
# test_predictions <- predict(step_model, newdata = test_data, type = "response")
# threshold <- 0.5
# test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
ci <- confint(step_model)
print(ci)
exp(coef(step_model))
exp(cbind(OR <- coef(step_model), ci))
library('MASS')
library('caret')
# 加载数据
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
# 合并数据集并划分
data <- cbind(X, y)
set.seed(12) # 123
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices)) # 修改比例
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
# Logistic Regression using stepAIC
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary.glm(step_model)
# test_predictions <- predict(step_model, newdata = test_data, type = "response")
# threshold <- 0.5
# test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
ci <- confint(step_model)
print(ci)
exp(coef(step_model))
exp(cbind(OR <- coef(step_model), ci))
library('MASS')
library('caret')
# 加载数据
X <- read.csv("X.csv", header = TRUE)
y <- read.csv("y.csv", header = TRUE)
# 合并数据集并划分
data <- cbind(X, y)
set.seed(125) # 123
indices <- 1:nrow(data)
shuffled_indices <- sample(indices)
train_size <- floor(0.7 * length(indices)) # 修改比例
train_indices <- shuffled_indices[1:train_size]
test_indices <- shuffled_indices[(train_size + 1):length(indices)]
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
# Logistic Regression using stepAIC
logit_model <- glm(dod ~ ., data = train_data, family = binomial)
step_model <- stepAIC(logit_model, direction = "both")
summary.glm(step_model)
# test_predictions <- predict(step_model, newdata = test_data, type = "response")
# threshold <- 0.5
# test_predictions_binary <- ifelse(test_predictions > threshold, 1, 0)
ci <- confint(step_model)
print(ci)
exp(coef(step_model))
exp(cbind(OR <- coef(step_model), ci))
View(step_model)
step_model[["R"]]
